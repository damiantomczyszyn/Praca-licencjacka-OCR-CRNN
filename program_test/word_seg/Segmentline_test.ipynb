{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from spellchecker import SpellChecker\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dominant_color(image):\n",
    "        #Resizing parameters\n",
    "        width, height = 150,150\n",
    "        image = image.resize((width, height),resample = 0)\n",
    "        #Get colors from image object\n",
    "        pixels = image.getcolors(width * height)\n",
    "        #Sort them by count number(first element of tuple)\n",
    "        sorted_pixels = sorted(pixels, key=lambda t: t[0])\n",
    "        #Get the most frequent color\n",
    "        dominant_color = sorted_pixels[-1][1]\n",
    "        return dominant_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img, imgSize):\n",
    "    \"put img into target img of size imgSize, transpose for TF and normalize gray-values\"\n",
    "\n",
    "    # there are damaged files in IAM dataset - just use black image instead\n",
    "    if img is None:\n",
    "        img = np.zeros([imgSize[1], imgSize[0]]) \n",
    "        print(\"Image None!\")\n",
    "\n",
    "    # create target image and copy sample image into it\n",
    "    (wt, ht) = imgSize\n",
    "    (h, w) = img.shape\n",
    "    fx = w / wt\n",
    "    fy = h / ht\n",
    "    f = max(fx, fy)\n",
    "    newSize = (max(min(wt, int(w / f)), 1),\n",
    "               max(min(ht, int(h / f)), 1))  # scale according to f (result at least 1 and at most wt or ht)\n",
    "    img = cv2.resize(img, newSize, interpolation=cv2.INTER_CUBIC) # INTER_CUBIC interpolation best approximate the pixels image\n",
    "                                                               # see this https://stackoverflow.com/a/57503843/7338066\n",
    "    most_freq_pixel=find_dominant_color(Image.fromarray(img))\n",
    "    target = np.ones([ht, wt]) * most_freq_pixel  \n",
    "    target[0:newSize[1], 0:newSize[0]] = img\n",
    "\n",
    "    img = target\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_img(img):\n",
    "    old_h,old_w=img.shape[0],img.shape[1]\n",
    "\n",
    "    #Pad the height.\n",
    "\n",
    "    #If height is less than 512 then pad to 512\n",
    "    if old_h<512:\n",
    "        to_pad=np.ones((512-old_h,old_w))*255\n",
    "        img=np.concatenate((img,to_pad))\n",
    "        new_height=512\n",
    "    else:\n",
    "    #If height >512 then pad to nearest 10.\n",
    "        to_pad=np.ones((roundup(old_h)-old_h,old_w))*255\n",
    "        img=np.concatenate((img,to_pad))\n",
    "        new_height=roundup(old_h)\n",
    "\n",
    "    #Pad the width.\n",
    "    if old_w<512:\n",
    "        to_pad=np.ones((new_height,512-old_w))*255\n",
    "        img=np.concatenate((img,to_pad),axis=1)\n",
    "        new_width=512\n",
    "    else:\n",
    "        to_pad=np.ones((new_height,roundup(old_w)-old_w))*255\n",
    "        img=np.concatenate((img,to_pad),axis=1)\n",
    "        new_width=roundup(old_w)-old_w\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundup(x):\n",
    "    return int(math.ceil(x / 10.0)) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 22:33:19.280713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 22:33:19.285372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 22:33:19.285542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 22:33:19.286133: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-09 22:33:19.310656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 22:33:19.310891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 22:33:19.311073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 22:33:20.363518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 22:33:20.363692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 22:33:20.363817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 22:33:20.363935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 217 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "2022-04-09 22:33:20.368350: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 217.25M (227803136 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 22:33:20.368776: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 195.52M (205022976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 22:33:20.430695: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 41.28M (43282432 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 22:33:20.431128: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 41.28M (43282432 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 22:33:30.432258: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 41.28M (43282432 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 22:33:30.433212: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 41.28M (43282432 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 22:33:30.433239: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 36.00MiB (rounded to 37748736)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-04-09 22:33:30.433251: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-04-09 22:33:30.433261: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 10, Chunks in use: 10. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 544B client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433270: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433279: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 3, Chunks in use: 3. 3.2KiB allocated for chunks. 3.2KiB in use in bin. 3.0KiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433287: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 3, Chunks in use: 3. 6.2KiB allocated for chunks. 6.2KiB in use in bin. 6.2KiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433295: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433303: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433310: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433318: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433325: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433335: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433344: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 3, Chunks in use: 1. 855.5KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433353: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 576.0KiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433362: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 1. 3.38MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433370: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 1. 2.25MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433379: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 1. 13.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433387: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433396: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 3, Chunks in use: 1. 54.00MiB allocated for chunks. 18.00MiB in use in bin. 18.00MiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433405: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 2. 92.29MiB allocated for chunks. 92.29MiB in use in bin. 72.00MiB client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433413: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433420: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433429: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 22:33:30.433437: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 36.00MiB was 32.00MiB, Chunk State: \n",
      "2022-04-09 22:33:30.433443: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 184520704\n",
      "2022-04-09 22:33:30.433454: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000000 of size 1280 next 1\n",
      "2022-04-09 22:33:30.433460: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000500 of size 256 next 2\n",
      "2022-04-09 22:33:30.433466: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000600 of size 256 next 3\n",
      "2022-04-09 22:33:30.433472: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000700 of size 256 next 4\n",
      "2022-04-09 22:33:30.433478: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000800 of size 256 next 7\n",
      "2022-04-09 22:33:30.433483: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000900 of size 256 next 8\n",
      "2022-04-09 22:33:30.433489: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000a00 of size 256 next 9\n",
      "2022-04-09 22:33:30.433496: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000b00 of size 512 next 14\n",
      "2022-04-09 22:33:30.433501: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000d00 of size 256 next 15\n",
      "2022-04-09 22:33:30.433507: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c000e00 of size 512 next 16\n",
      "2022-04-09 22:33:30.433513: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c001000 of size 1024 next 21\n",
      "2022-04-09 22:33:30.433519: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c001400 of size 256 next 22\n",
      "2022-04-09 22:33:30.433525: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c001500 of size 1024 next 5\n",
      "2022-04-09 22:33:30.433531: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c001900 of size 2304 next 6\n",
      "2022-04-09 22:33:30.433537: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c002200 of size 2048 next 27\n",
      "2022-04-09 22:33:30.433543: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c002a00 of size 256 next 28\n",
      "2022-04-09 22:33:30.433548: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c002b00 of size 2048 next 29\n",
      "2022-04-09 22:33:30.433556: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c003300 of size 4096 next 34\n",
      "2022-04-09 22:33:30.433562: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c004300 of size 256 next 35\n",
      "2022-04-09 22:33:30.433568: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5a5c004400 of size 286208 next 10\n",
      "2022-04-09 22:33:30.433574: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c04a200 of size 147456 next 11\n",
      "2022-04-09 22:33:30.433579: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5a5c06e200 of size 294912 next 12\n",
      "2022-04-09 22:33:30.433585: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c0b6200 of size 294912 next 13\n",
      "2022-04-09 22:33:30.433591: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5a5c0fe200 of size 1179648 next 17\n",
      "2022-04-09 22:33:30.433597: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c21e200 of size 589824 next 18\n",
      "2022-04-09 22:33:30.433603: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5a5c2ae200 of size 1179648 next 19\n",
      "2022-04-09 22:33:30.433609: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c3ce200 of size 1179648 next 20\n",
      "2022-04-09 22:33:30.433615: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5a5c4ee200 of size 4718592 next 24\n",
      "2022-04-09 22:33:30.433621: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5c96e200 of size 2359296 next 25\n",
      "2022-04-09 22:33:30.433627: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5a5cbae200 of size 4718592 next 23\n",
      "2022-04-09 22:33:30.433633: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5d02e200 of size 4718592 next 26\n",
      "2022-04-09 22:33:30.433639: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5a5d4ae200 of size 18874368 next 30\n",
      "2022-04-09 22:33:30.433645: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a5e6ae200 of size 9437184 next 31\n",
      "2022-04-09 22:33:30.433650: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5a5efae200 of size 18874368 next 32\n",
      "2022-04-09 22:33:30.433657: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a601ae200 of size 18874368 next 33\n",
      "2022-04-09 22:33:30.433663: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a613ae200 of size 37748736 next 36\n",
      "2022-04-09 22:33:30.433669: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5a637ae200 of size 59026944 next 18446744073709551615\n",
      "2022-04-09 22:33:30.433675: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-04-09 22:33:30.433683: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 10 Chunks of size 256 totalling 2.5KiB\n",
      "2022-04-09 22:33:30.433690: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2022-04-09 22:33:30.433697: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 1024 totalling 2.0KiB\n",
      "2022-04-09 22:33:30.433703: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-04-09 22:33:30.433710: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 2048 totalling 4.0KiB\n",
      "2022-04-09 22:33:30.433717: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2304 totalling 2.2KiB\n",
      "2022-04-09 22:33:30.433723: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 4096 totalling 4.0KiB\n",
      "2022-04-09 22:33:30.433730: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 147456 totalling 144.0KiB\n",
      "2022-04-09 22:33:30.433737: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 294912 totalling 288.0KiB\n",
      "2022-04-09 22:33:30.433744: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2022-04-09 22:33:30.433751: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1179648 totalling 1.12MiB\n",
      "2022-04-09 22:33:30.433757: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2359296 totalling 2.25MiB\n",
      "2022-04-09 22:33:30.433764: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 4718592 totalling 4.50MiB\n",
      "2022-04-09 22:33:30.433770: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 9437184 totalling 9.00MiB\n",
      "2022-04-09 22:33:30.433777: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 18874368 totalling 18.00MiB\n",
      "2022-04-09 22:33:30.433784: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 37748736 totalling 36.00MiB\n",
      "2022-04-09 22:33:30.433791: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 59026944 totalling 56.29MiB\n",
      "2022-04-09 22:33:30.433798: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 128.17MiB\n",
      "2022-04-09 22:33:30.433804: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 184520704 memory_limit_: 227803136 available bytes: 43282432 curr_region_allocation_bytes_: 455606272\n",
      "2022-04-09 22:33:30.433815: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                       227803136\n",
      "InUse:                       134394368\n",
      "MaxInUse:                    134394368\n",
      "NumAllocs:                          47\n",
      "MaxAllocSize:                 59026944\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-04-09 22:33:30.433825: W tensorflow/core/common_runtime/bfc_allocator.cc:474] ***__**__***_________*******_________****************************************************xxxxxxxxxxx\n",
      "2022-04-09 22:33:30.437765: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m       model\u001b[38;5;241m.\u001b[39mload_weights(pretrained_weights)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 53\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./word_seg_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msort_word\u001b[39m(wordlist):\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36munet\u001b[0;34m(pretrained_weights, input_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m pool4 \u001b[38;5;241m=\u001b[39m MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))(drop4)\n\u001b[1;32m     17\u001b[0m conv5 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m3\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m)(pool4)\n\u001b[0;32m---> 18\u001b[0m conv5 \u001b[38;5;241m=\u001b[39m \u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhe_normal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m drop5 \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m)(conv5)\n\u001b[1;32m     21\u001b[0m up6 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m2\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m)(UpSampling2D(size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))(drop5))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/backend.py:1930\u001b[0m, in \u001b[0;36mRandomGenerator.truncated_normal\u001b[0;34m(self, shape, mean, stddev, dtype)\u001b[0m\n\u001b[1;32m   1927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator:\n\u001b[1;32m   1928\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator\u001b[38;5;241m.\u001b[39mtruncated_normal(\n\u001b[1;32m   1929\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape, mean\u001b[38;5;241m=\u001b[39mmean, stddev\u001b[38;5;241m=\u001b[39mstddev, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m-> 1930\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruncated_normal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstddev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_legacy_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "\n",
    "def unet(pretrained_weights = None,input_size = (512,512,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs,conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "\n",
    "    if(pretrained_weights):\n",
    "      model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "model=unet()\n",
    "model.load_weights('word_seg_model.h5')\n",
    "\n",
    "\n",
    "\n",
    "def sort_word(wordlist):\n",
    "    wordlist.sort(key=lambda x:x[0])\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def segment_into_words(line_img,idx):\n",
    "    \"\"\"This function takes in the line image and line index returns word images and the reference\n",
    "    of line they belong to.\"\"\"\n",
    "    img=pad_img(line_img)\n",
    "    ori_img=img.copy()\n",
    "    #ori_img=np.stack((ori_img,)*3, axis=-1)\n",
    "    ret,img=cv2.threshold(img,150,255,cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    img=cv2.resize(img,(512,512))\n",
    "    img=np.expand_dims(img,axis=-1)\n",
    "    img=img/255\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    seg_pred=model.predict(img)\n",
    "    seg_pred=np.squeeze(np.squeeze(seg_pred,axis=0),axis=-1)\n",
    "    seg_pred=cv2.normalize(src=seg_pred, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "    cv2.threshold(seg_pred,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU,seg_pred)\n",
    "    contours, hier = cv2.findContours(seg_pred, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    (H, W) = ori_img.shape[:2]\n",
    "    (newW, newH) = (512, 512)\n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "\n",
    "    coordinates=[]\n",
    "\n",
    "    for c in contours:\n",
    "        # get the bounding rect\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        # draw a white rectangle to visualize the bounding rect\n",
    "        # cv2.rectangle(ori_img, (int(x*rW), int(y*rH)), (int((x+w)*rW),int((y+h)*rH)), (255,0,0), 1)\n",
    "        coordinates.append((int(x*rW),int(y*rH),int((x+w)*rW),int((y+h)*rH)))\n",
    "\n",
    "    coordinates=sort_word(coordinates)  #Sorting according to x-coordinates.\n",
    "    word_counter=0\n",
    "\n",
    "    word_array=[]\n",
    "    line_indicator=[]\n",
    "\n",
    "    for (x1,y1,x2,y2) in coordinates:\n",
    "        word_img=ori_img[y1:y2,x1:x2]\n",
    "        word_img=preprocess_img(word_img,(128,32))\n",
    "        word_img=np.expand_dims(word_img,axis=-1)\n",
    "        word_array.append(word_img)\n",
    "        line_indicator.append(idx)\n",
    "\n",
    "    return line_indicator,word_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Word_Segmentation_UNet_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
